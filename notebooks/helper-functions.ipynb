{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions for PlaineMorte.jl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using NBInclude\n",
    "#Call the different paths needed\n",
    "@nbinclude(\"paths_download.ipynb\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Constant definition\n",
    "g = 9.81\n",
    "rhow = 1000.0;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using LsqFit # a package for least square fitting\n",
    "using MonteCarloMeasurements\n",
    "\n",
    "\"\"\"\n",
    "    curve_fit_MCMeasurements(model, x, y, p0)\n",
    "\n",
    "Does LsqFit.curve_fit with MonteCarloMeasurements Vectors.  Same input as `curve_fit`.\n",
    "\"\"\"\n",
    "function curve_fit_MCMeasurements(model, x, y, p0)\n",
    "    if eltype(x)<:Particles && eltype(y)<:Particles\n",
    "        len = length(x[1].particles)\n",
    "        pout = [eltype(p0)[] for p in p0]\n",
    "        for i=1:len\n",
    "            p = curve_fit(model, [xx.particles[i] for xx in x], [yy.particles[i] for yy in y], p0)\n",
    "            @assert p.converged\n",
    "            for j=1:length(p0)\n",
    "                push!(pout[j], p.param[j])\n",
    "            end\n",
    "        end\n",
    "    elseif eltype(y)<:Particles\n",
    "        len = length(y[1].particles)\n",
    "        pout = [eltype(p0)[] for p in p0]\n",
    "        for i=1:len\n",
    "            p = curve_fit(model, x, [yy.particles[i] for yy in y], p0)\n",
    "            @assert p.converged \"$i\"\n",
    "            for j=1:length(p0)\n",
    "                push!(pout[j], p.param[j])\n",
    "            end\n",
    "        end\n",
    "    elseif eltype(x)<:Particles\n",
    "        len = length(x[1].particles)\n",
    "        pout = [eltype(p0)[] for p in p0]\n",
    "        for i=1:len\n",
    "            p = curve_fit(model, [xx.particles[i] for xx in x], y, p0)\n",
    "            @assert p.converged\n",
    "            for j=1:length(p0)\n",
    "                push!(pout[j], p.param[j])\n",
    "            end\n",
    "        end\n",
    "    else\n",
    "        error()\n",
    "    end\n",
    "    return [Particles(po) for po in pout]\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    fit_calibration(bucketsize, solution, calis...)\n",
    "\n",
    "Fits a line of best fit through the calibration data going through the origin.  \n",
    "Returns the function of this line: `f(cond-cond_at_0) -> concentration`.\n",
    "\n",
    "Also prints the parameters values +/- 95% confidence intervals.\n",
    "\n",
    "Uses the package LsqFit: https://github.com/JuliaOpt/LsqFit.jl\n",
    "\"\"\"\n",
    "function fit_calibration(bucketsize, solution, calis...)\n",
    "    # subtract readout at zero concentration\n",
    "    for c in calis\n",
    "        @assert c[1,1]==0 \"First row needs to be zero reading!\"\n",
    "        c[:,2] .= c[:,2].-c[1,2]\n",
    "    end\n",
    "    \n",
    "    #first compute ml_to_concentration : both bucketsize and solution has n values for n element in cali\n",
    "\n",
    "    #then only concatenate all concentration\n",
    "    #conc=vcat(c1,c2..)\n",
    "    \n",
    "    # concatenate all calibrations\n",
    "    \n",
    "    cali = vcat(calis...)\n",
    "    conc = ml_to_concentration(cali[:,1], solution, bucketsize)\n",
    "    delta_readout = cali[:,2]\n",
    "    # Fit line using https://github.com/JuliaOpt/LsqFit.jl\n",
    "    fn(delta_readout, p) = p[1]*delta_readout # p[1]==a, p[2]==b\n",
    "    para_weights = [0.5] # equal weights to parameters\n",
    "    fit = curve_fit(fn, delta_readout, conc, para_weights)\n",
    "    errors = margin_error(fit, 1-0.95)\n",
    "    println(\"\"\"\n",
    "    Estimated linear fit: f(delta_cond) = a*conc with (margin errors 5%)\n",
    "     a = $(round(fit.param[1],sigdigits=3))±$(round(errors[1],sigdigits=3))\n",
    "    \"\"\")\n",
    "    return (delta_readout) -> fn(delta_readout, fit.param)\n",
    "    \n",
    "    \n",
    "end;\n",
    "\n",
    "\"\"\"\n",
    "    fit_calibration_LAB_2000(calis...)\n",
    "ONLY for LAB experiment conducted the 9th October, using the 0-2000 μS/cm range. Because of the unique protocol \n",
    "of dilution (Both Solution 1g/l and 10g/l were used).\n",
    "Fits a line of best fit through the calibration data going through the origin.  \n",
    "Returns the function of this line: `f(cond-cond_at_0) -> concentration`.\n",
    "\n",
    "Also prints the parameters values +/- 95% confidence intervals.\n",
    "\n",
    "Uses the package LsqFit: https://github.com/JuliaOpt/LsqFit.jl\n",
    "\"\"\"\n",
    "\n",
    "function fit_calibration_LAB_2000(calis...)\n",
    "    # subtract readout at zero concentration\n",
    "    for c in calis\n",
    "        @assert c[1,1]==0 \"First row needs to be zero reading!\"\n",
    "        c[:,2] .= c[:,2].-c[1,2]\n",
    "    end\n",
    "    cali = vcat(calis...)\n",
    "    conc1 = ml_to_concentration(cali[1:10,1], solution1, bucketsize2);\n",
    "    conc2 = ml_to_concentration(cali[11:19,1], solution2, bucketsize2) .+ conc1[end]\n",
    "    conc= vcat(conc1,conc2)\n",
    "    delta_readout = cali[:,2] #conductivity\n",
    "\n",
    "    # Fit line using https://github.com/JuliaOpt/LsqFit.jl\n",
    "    fn(delta_readout, p) = p[1]*delta_readout.^2 + p[2]*delta_readout;  # p[1]==a, p[2]==b  \n",
    "    para_weights = [0.5, 0.5] # equal weights to parameters\n",
    "    fit = curve_fit(fn, delta_readout, conc, para_weights)\n",
    "    errors = margin_error(fit, 1-0.95)\n",
    "    #standard error\n",
    "    sigma = stderror(fit)  #size of fit.param\n",
    "    \n",
    "    println(\"\"\"\n",
    "    Estimated fit: f(delta_cond) = a*conc^2 + b*conc with (± std dev)\n",
    "     a = $(round(fit.param[1],sigdigits=3))±$(round(sigma[1],sigdigits=3))\n",
    "        and b = $(round(fit.param[2],sigdigits=3))±$(round(sigma[2],sigdigits=3))\n",
    "    \"\"\")\n",
    "    #I write again the function fitted but with errors associated, to calculate conc ± σ from cond ± σ\n",
    "    \n",
    "    cond2conc(delta_readout, p, err) =(p[1] ± err[1])*delta_readout.^2 + (p[2] ± err[2])*delta_readout\n",
    "    \n",
    "    \n",
    "    return (delta_readout) -> cond2conc(delta_readout ± 0, fit.param, sigma) #Unstable for little conductivity...\n",
    "    \n",
    "end;\n",
    "\n",
    "\"\"\"\n",
    "    fit_calibration_LAB_200(calis...)\n",
    "\n",
    "Similary to fit_calibration_2000 but in the 0-2000 μS/cm range, it is specialy made for the 10th october calibration.\n",
    "\"\"\"\n",
    "\n",
    "function fit_calibration_LAB_200(calis...)\n",
    "    # subtract readout at zero concentration\n",
    "    for c in calis\n",
    "        @assert c[1,1]==0 \"First row needs to be zero reading!\"\n",
    "        c[:,2] .= c[:,2].-c[1,2]\n",
    "    end\n",
    "    cali = vcat(calis...)\n",
    "    \n",
    "    conc3 = ml_to_concentration(cali[1:10,1], solution1, bucketsize2);\n",
    "    conc4 = ml_to_concentration(cali[11:20,1], solution2, bucketsize2) .+ conc3[end]\n",
    "    conc= vcat(conc3,conc4)\n",
    "    delta_readout = cali[:,2]\n",
    "\n",
    "    # Fit line using https://github.com/JuliaOpt/LsqFit.jl\n",
    "    fn(delta_readout, p) = p[1]*delta_readout \n",
    "    para_weights = [0.5] # equal weights to parameters\n",
    "    fit = curve_fit(fn, delta_readout, conc, para_weights)\n",
    "    errors = margin_error(fit, 1-0.95)\n",
    "    sigma = stderror(fit)\n",
    "    println(\"\"\"\n",
    "    Estimated fit: f(delta_cond) = a*conc with (± std dev)\n",
    "     a = $(round(fit.param[1],sigdigits=3))±$(round(sigma[1],sigdigits=3)) \n",
    "    \"\"\")\n",
    "    return (delta_readout) -> fn(delta_readout, fit.param)\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "read_salt_injections (generic function with 1 method)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Dates\n",
    "using DelimitedFiles: readdlm # Date time handling; CSV file handling\n",
    "\n",
    "\"\"\"\n",
    "    read_salt_injections(filename)\n",
    "    To read all the salt injection (location, time, mass injected...) from the \n",
    "appropriate CSV file\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "function read_salt_injections(filename)\n",
    "    if !isfile(filename)\n",
    "        error(\"Filename $filename is not a file!\")\n",
    "    end\n",
    "    d, head = readdlm(filename, ';', header=true)\n",
    "    out = Dict{Symbol,Any}() \n",
    "    # Numero injection\n",
    "    out[:num] = d[:,1]\n",
    "    # Date\n",
    "    fmtd = \"d/m/y\"\n",
    "    out[:d] = [Date(dd, fmtd) for dd in d[:,2]]\n",
    "    #Time\n",
    "    fmtt = \"H:M:S\"\n",
    "    out[:t] = [Time(dd, fmtt) for dd in d[:,3]]\n",
    "    # location\n",
    "    out[:inj] = d[:,4]\n",
    "    # Mass\n",
    "    out[:mass] = d[:,5]\n",
    "    return out\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"C:\\\\Users\\\\christophe\\\\Desktop\\\\home\\\\GitHub\\\\PlaineMorteLake_hydro_thermodynamics\\\\notebooks\\\\../data/CTD/\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_CTD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Air Pressure Reccord in summer 2019 from Fribourg station on Plaine Morte (2690 m)\n",
    "using Dates\n",
    "using DelimitedFiles: readdlm \n",
    "p, head = readdlm(joinpath(path_CTD, \"PLM_atmo_pressure/PLM_atmo_pressure_2019.csv\"), ';', header=true)\n",
    "    p_atm = Dict{Symbol,Any}() \n",
    "    # DateTime\n",
    "    fmtdt = \"d.m.y H:M:S\"\n",
    "    p_atm[:t] = [DateTime(pp, fmtdt)+Dates.Hour(2) for pp in p[:,1]];  #UTM to UTC conversion\n",
    "    # Air pressure\n",
    "    p_atm[:press] = p[:,2];\n",
    "\n",
    "#Air Pressure Reccord in summer 2020 from Fribourg station on Plaine Morte (2690 m)\n",
    "p, head = readdlm(joinpath(path_CTD, \"PLM_atmo_pressure/PLM_atmo_pressure_2020.csv\"), ';', header=true)\n",
    "    p_atm_2020 = Dict{Symbol,Any}() \n",
    "    # DateTime\n",
    "    fmtdt = \"d.m.y H:M:S\"\n",
    "    p_atm_2020[:t] = [DateTime(pp, fmtdt) for pp in p[:,1]];  #raw data already in ETC Time\n",
    "    # Air pressure\n",
    "    p_atm_2020[:press] = p[:,2];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "read_Keller_DC22 (generic function with 1 method)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Dates\n",
    "using DelimitedFiles: readdlm # Date time handling; CSV file handling\n",
    "\n",
    "# These will read files containing time series of a combination of the following sensors:\n",
    "# conductivity, pressure, temperature\n",
    "# The convention is to return a dict with keys as appropriate:\n",
    "# :t [date-time stamp], :cond [μS/cm], :temp [C], :press [m H2O]\n",
    "#\n",
    "# (Note, the funny \":\" in front of the name makes a special kind of string, a so-called Symbol)\n",
    "\n",
    "\"\"\"\n",
    "    read_WTW(filename)\n",
    "\n",
    "This function reads a file from the WTW conductivity sensor and\n",
    "returns:\n",
    "\n",
    "Dict with keys: :t [date-time stamp], :cond [μS/cm], :temp [C]\n",
    "\n",
    "Note, that the input file usually contains several traces.  Split them up with \n",
    "`split_conductivity_data`.\n",
    "\"\"\"\n",
    "function read_WTW(filename)\n",
    "    if !isfile(filename)\n",
    "        error(\"Filename $filename is not a file!\")\n",
    "    end\n",
    "    if !startswith(splitdir(filename)[2], \"AD\")\n",
    "        warn(\"Read in a file starting with `AD`.  (The `AC` files use a comma for the decimal point.\")\n",
    "    end\n",
    "    d, head = readdlm(filename, ';', header=true)\n",
    "    out = Dict{Symbol,Any}() # key has the be Symbol, value can be anything\n",
    "    # time 12.08.2016 13:36:58\n",
    "    fmt = \"d.m.y H:M:S\"\n",
    "    out[:t] = [DateTime(dd, fmt) for dd in d[:,4]]\n",
    "    # conductivity\n",
    "    out[:cond] = d[:,5]\n",
    "    units = d[:,6]\n",
    "    @assert all(units.==\"\\xb5S/cm\") \"Units not in μS/cm!\"\n",
    "    # temp\n",
    "    out[:temp] = d[:,8]\n",
    "    \n",
    "    # purge any records which are simultaneous (not sure why this happens with the WTW)\n",
    "    purge = findall(diff(out[:t]).==Second(0))\n",
    "    for p in reverse(purge)\n",
    "        deleteat!(out[:t], p)\n",
    "        deleteat!(out[:cond],p)\n",
    "        deleteat!(out[:temp], p)\n",
    "    end\n",
    "\n",
    "    return out\n",
    "end\n",
    "\n",
    "\n",
    "using DelimitedFiles, Dates\n",
    "\n",
    "\n",
    "#temperature calibration datas (°C) in lab from Temperature_calibration\n",
    "sensor_T = Dict() \n",
    "sensor_T[205144]=-0.104\n",
    "sensor_T[205145]=0.076\n",
    "sensor_T[205309]=-0.021\n",
    "sensor_T[207265]=-0.319\n",
    "sensor_TOB1 = Dict() \n",
    "sensor_TOB1[205144]=-0.123\n",
    "sensor_TOB1[205145]=0.002\n",
    "sensor_TOB1[205309]=0.018\n",
    "sensor_TOB1[207265]=0.161\n",
    "\n",
    "\"\"\"\n",
    "         read_Keller(filename;\n",
    "                     presshead=\"P1\",\n",
    "                     condhead=\"ConRaw\",\n",
    "                     temphead=\"TOB1\",\n",
    "                     skipstart=8,\n",
    "                     )\n",
    "\n",
    "Reads a Keller pressure/CTD sensor.  However, you probably want to use\n",
    "- `read_Keller_DCX22_CTD`, \n",
    "- `read_Keller_DCX22` and \n",
    "- `read_Keller_DC22` \n",
    "\n",
    "Returns a dict with keys as appropriate:\n",
    "- :t [date-time stamp]\n",
    "- :cond [μS/cm]\n",
    "- :temp [C]\n",
    "- :press [m H2O]\n",
    "\"\"\"\n",
    "function read_Keller(filename;\n",
    "                     presshead=\"P1\",\n",
    "                     condhead=\"ConRaw\",\n",
    "                     temphead=\"TOB1\",\n",
    "                     temphead2=\"T\",\n",
    "                     skipstart=8,\n",
    "                     )\n",
    "    \n",
    "    #extract sensor serial number\n",
    "    s = filename[length(path_CTD)+12:length(path_CTD)+17]\n",
    "    #We adapt the filename according to the user (difference in paths)\n",
    "    #for christophe local machine s=filename[99:104]\n",
    "    #for vaw new computer s=filename[92:97]\n",
    "    sensor=parse(Int, s)\n",
    "    \n",
    "    #read the CSV\n",
    "    d,h = readdlm(filename, ';', skipstart=skipstart, header=true)\n",
    "    h = h[:] # h is a 1x2 matrix, change to a vector\n",
    "\n",
    "    out = Dict{Symbol,Any}()\n",
    "    # find date-time rows\n",
    "    id, it = findfirst(h.==\"Date\"), findfirst(h.==\"Time\")\n",
    "    # time 12.08.2016 13:36:58\n",
    "    fmtd, fmtt = \"d/m/y\", \"H:M:S\"\n",
    "    out[:t] = [Date(dd, fmtd) + Time(tt, fmtt) for (dd,tt) in zip(d[:,id], d[:,it])]\n",
    "\n",
    "    #\n",
    "    for (head, key) in [(presshead, :press),\n",
    "                        (condhead, :cond),\n",
    "                        (temphead, :temp),\n",
    "                       (temphead2, :temp2)]\n",
    "        i = findfirst(h.==head) # see if there is one\n",
    "        tmp = Float64[]\n",
    "        if i!=nothing\n",
    "            out[key] = [s==\"\" ? missing :\n",
    "                        s isa AbstractString ? parse(Float64, replace(s, \",\"=>\".\")) : Float64(s) for s in d[:,i]]\n",
    "            # convert mS/cm to μS/cm\n",
    "            if key==:cond\n",
    "                out[:cond] = out[:cond].*1000\n",
    "            end\n",
    "            #correct temperature for each sensor\n",
    "            if key==:temp\n",
    "                out[:temp]=out[:temp].-sensor_TOB1[sensor]\n",
    "            end\n",
    "            if key==:temp2\n",
    "                out[:temp2]=out[:temp2].-sensor_T[sensor]\n",
    "            end\n",
    "            \n",
    "            # convert pressure from mbar to m H2O\n",
    "            if key==:press \n",
    "                if out[:t][1]> DateTime(2019,9,5)\n",
    "                   out[:press] = out[:press]  #No atm correction availbale after 4th September\n",
    "                else\n",
    "                    j=1 \n",
    "                    while p_atm[:t][j] <=out[:t][1]   #start of air pressure record\n",
    "                    j=j+1\n",
    "                     end       #p_atm[:t][j] is then the start ot air pressure time serie matching the :press time serie\n",
    "                     \n",
    "                     for i in 1:length(out[:t])\n",
    "                        if out[:t][i]<=p_atm[:t][j]  \n",
    "                            out[:press][i] = ((out[:press][i].-p_atm[:press][j]).*1e2./(g*rhow)).+0.05 #5cm correction from data readings (Δz=39m ?)\n",
    "\n",
    "                        else\n",
    "                            j=j+1\n",
    "                            out[:press][i] = ((out[:press][i].-p_atm[:press][j]).*1e2./(g*rhow)).+0.05\n",
    "                        \n",
    "                        end\n",
    "                 \n",
    "                     end\n",
    "                end\n",
    "              \n",
    "                end    \n",
    "                    \n",
    "             end \n",
    "        end\n",
    "      \n",
    "    \n",
    "     # purge any records which are simultaneous (not sure why this happens with the WTW)\n",
    "    purge = findall(diff(out[:t]).==Second(0))\n",
    "    for p in reverse(purge)\n",
    "        deleteat!(out[:t], p)\n",
    "        deleteat!(out[:cond],p)\n",
    "        deleteat!(out[:temp], p)\n",
    "        deleteat!(out[:temp2], p)\n",
    "        deleteat!(out[:press], p)\n",
    "    end\n",
    " \n",
    "    # check lengths and remove all \"missing\"\n",
    "    l = length(out[:t])\n",
    "    topurge = []\n",
    "    for v in values(out)\n",
    "        @assert length(v)==l\n",
    "        append!(topurge, findall(v.===missing))\n",
    "    end\n",
    "    topurge = sort(unique(topurge))\n",
    "    for (k,v) in out\n",
    "        deleteat!(v, topurge)\n",
    "        if k!=:t\n",
    "            out[k] = Float64.(v) # make the vector an\n",
    "        end\n",
    "    end\n",
    "    return out\n",
    "end\n",
    "\n",
    "read_Keller_DCX22_CTD(filename) = read_Keller(filename)  #Actually, read_Keller function is already adapted to CTD\n",
    "\n",
    "#A dedicated function to read Keller DCX-22\n",
    "function read_Keller_DCX22(filename;\n",
    "                            presshead=\"P1\",\n",
    "                            temphead=\"TOB1\",\n",
    "                            skipstart=8)\n",
    "    if !isfile(filename)\n",
    "        error(\"Filename $filename is not a file!\")\n",
    "    end                                   \n",
    "    \n",
    "    #read the CSV\n",
    "    d,h = readdlm(filename, ';', skipstart=skipstart, header=true)\n",
    "    h = h[:] # h is a 1x2 matrix, change to a vector\n",
    "\n",
    "    out = Dict{Symbol,Any}()\n",
    "    # find date-time rows\n",
    "    id, it = findfirst(h.==\"Date\"), findfirst(h.==\"Time\")\n",
    "    # time 12.08.2016 13:36:58\n",
    "    fmtd, fmtt = \"d.m.y\", \"H:M:S\"\n",
    "    out[:t] = [Date(dd, fmtd) + Time(tt, fmtt) for (dd,tt) in zip(d[:,id], d[:,it])]\n",
    "    \n",
    "    for (head, key) in [(presshead, :press),\n",
    "                        (temphead, :temp)]\n",
    "        i = findfirst(h.==head) # see if there is one\n",
    "        tmp = Float64[]\n",
    "        if i!=nothing\n",
    "            out[key] = [s==\"\" ? missing :\n",
    "                    s isa AbstractString ? parse(Float64, replace(s, \",\"=>\".\")) : Float64(s) for s in d[:,i]]\n",
    "         \n",
    "            \n",
    "            if key==:press \n",
    "                # convert pressure from mbar to m H2O\n",
    "                #correction available for 1 August -> 1 September 2020 (Plaine Morte Fribourg station)\n",
    "                 \n",
    "                    j=1 \n",
    "                    while p_atm_2020[:t][j] <=out[:t][1]   #start of air pressure record\n",
    "                    j=j+1\n",
    "                    end       #p_atm_2020[:t][j] is then the start ot air pressure time serie matching the :press time serie\n",
    "                     \n",
    "                     for i in 1:length(out[:t])\n",
    "                        if out[:t][i]<=p_atm_2020[:t][j]  \n",
    "                            out[:press][i] = ((out[:press][i].-p_atm_2020[:press][j]).*1e2./(g*rhow)) \n",
    "\n",
    "                        else\n",
    "                            j=j+1\n",
    "                            out[:press][i] = ((out[:press][i].-p_atm_2020[:press][j]).*1e2./(g*rhow)) \n",
    "                        \n",
    "                        end\n",
    "                      \n",
    "            \n",
    "                end     \n",
    "            end \n",
    "        \n",
    "        end\n",
    "    end   \n",
    "    \n",
    "     # purge any records which are simultaneous (not sure why this happens with the WTW)\n",
    "    purge = findall(diff(out[:t]).==Second(0))\n",
    "    for p in reverse(purge)\n",
    "        deleteat!(out[:t], p)\n",
    "        deleteat!(out[:cond],p)\n",
    "        deleteat!(out[:temp], p)\n",
    "        deleteat!(out[:temp2], p)\n",
    "        deleteat!(out[:press], p)\n",
    "    end\n",
    " \n",
    "    # check lengths and remove all \"missing\"\n",
    "    l = length(out[:t])\n",
    "    topurge = []\n",
    "    for v in values(out)\n",
    "        @assert length(v)==l\n",
    "        append!(topurge, findall(v.===missing))\n",
    "    end\n",
    "    topurge = sort(unique(topurge))\n",
    "    for (k,v) in out\n",
    "        deleteat!(v, topurge)\n",
    "        if k!=:t\n",
    "            out[k] = Float64.(v) # make the vector an\n",
    "        end\n",
    "    end\n",
    "    return out\n",
    "end\n",
    "\n",
    "\n",
    "read_Keller_DC22(filename) = read_Keller(filename,\n",
    "                                         presshead=\"p1/mbar\",\n",
    "                                         temphead=\"t1/\\xb0C\",\n",
    "                                         skipstart=24\n",
    "                                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "plotit"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#using PyPlot\n",
    "\n",
    "\"\"\"\n",
    "   plotit(filename, sensor, variable)\n",
    "\n",
    "Plots the results from one file. \n",
    "\"\"\"\n",
    "function plotit(filename, sensor, variable=:cond ; plottime=true)\n",
    "    d = read_Keller_DCX22_CTD(filename)\n",
    "    # plot\n",
    "    fig=figure()\n",
    "    grid(true)\n",
    "    title(\"$filename, sensor=$sensor, variable=$variable\")\n",
    "    xlabel(\"Time\")\n",
    "    if variable==:cond\n",
    "        ylabel(\"Conductivity (μS//cm)\")\n",
    "        color=:blue\n",
    "        elseif variable==:press\n",
    "        ylabel(\"Water depth (m)\")\n",
    "        color=:blue\n",
    "        else variable==:temp\n",
    "        ylabel(\"Temperature (°C)\")\n",
    "        ylim(-0.1,5)\n",
    "        color=:red\n",
    "    end  \n",
    "    if plottime\n",
    "        plot(d[:t],d[variable],linestyle=\"-\",color,marker=\"None\")\n",
    "        fig[:autofmt_xdate](bottom=0.2,rotation=30,ha=\"right\")\n",
    "    else\n",
    "        plot(d[variable])\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    split_conductivity_data_indices(d, indices::Vector)\n",
    "\n",
    "Splits the CTD time series into separate traces according to passed in indices.\n",
    "\n",
    "Example:\n",
    "\n",
    "    traces = split_conductivity_data_indices(d, [500:3400, 5000:6789])\n",
    "\"\"\"\n",
    "function split_conductivity_data_indices(d, indices::Vector)\n",
    "    traces = []\n",
    "    t = d[:t]\n",
    "    for index in indices\n",
    "        tmp = Dict{Symbol,Any}()\n",
    "        tmp[:t] = convert(Vector{Float64}, Dates.value.(t[index]-t[index[1]])/1000)\n",
    "        tmp[:tstart] = t[index[1]]\n",
    "        tmp[:cond] = d[:cond][index]\n",
    "        if haskey(d, :temp)\n",
    "            tmp[:temp] = d[:temp][index]\n",
    "        end\n",
    "        if haskey(d, :press)\n",
    "            tmp[:press] = d[:press][index]\n",
    "        end\n",
    "        push!(traces, tmp)\n",
    "    end\n",
    "    \n",
    "    return traces\n",
    "end\n",
    "    \n",
    "\n",
    "\n",
    "\"\"\"\n",
    "    split_conductivity_data_timegap(outdict, timegap=5.0, mincond=0.5, maxtemp=2)\n",
    "\n",
    "Splits up the time series returned by `read_conductivity_data` into individual\n",
    "traces, mostly by using that there is a big time-gap in the record.\n",
    "\n",
    "First the datapoints which have `outdict[:cond]<mincond` or `outdict[:temp]>maxtemp` are deleted.\n",
    "Then, the split is done where the time-gap is bigger than `timegap` seconds.\n",
    "\n",
    "The output is a list of traces:\n",
    "\n",
    "`traces = [trace1, trace2, etc]`\n",
    "\n",
    "where `trace1` contains the time series with `:t` in seconds after recoding started, `:tstart` is \n",
    "the date-time of the start of the recording.  You should also add the injection `:mass` to each trace \n",
    "manually.\n",
    "\n",
    "Thus to access the times of the second trace do `traces[2][:t]`, and to get the corresponding\n",
    "conductivity readout `traces[2][:cond]`.\n",
    "\"\"\"\n",
    "function split_conductivity_data_timegap(out; timegap=5.0, mincond=0.0, maxtemp=2, minpeak=6, minduration=60)\n",
    "    # delete where cond<mincond and temp>maxtemp\n",
    "    out = deepcopy(out)\n",
    "    tokeep = (out[:cond].>mincond) .& (out[:temp].<maxtemp)\n",
    "    for (k,v) in out\n",
    "        out[k] = v[tokeep]\n",
    "    end\n",
    "\n",
    "    t = out[:t]\n",
    "    cond = out[:cond]   \n",
    "\n",
    "    # split it up according to time gaps\n",
    "    splits_at = findall(diff(t).>Second(timegap))\n",
    "    push!(splits_at, length(t))\n",
    "    traces = []\n",
    "    i = 1\n",
    "    for sp in splits_at\n",
    "        tt = convert(Vector{Float64}, Dates.value.(t[i:sp]-t[i])/1000)\n",
    "        dt = t[i+1]-t[i]\n",
    "        if !all(diff(t[i:sp]).==dt) \n",
    "            #@warn \"Logging intervals are not evenly spaced!\"\n",
    "        end\n",
    "        tmp = Dict{Symbol,Any}()\n",
    "        tmp[:t] = tt\n",
    "        if tt[end]-tt[1]<minduration\n",
    "            continue\n",
    "        end\n",
    "        tmp[:tstart] = t[i]\n",
    "        tmp[:cond] = cond[i:sp]\n",
    "        if maximum(tmp[:cond])<minpeak\n",
    "            continue\n",
    "        end\n",
    "        if haskey(out, :temp)\n",
    "            tmp[:temp] = out[:temp][i:sp]\n",
    "        end\n",
    "        if haskey(out, :press)\n",
    "            tmp[:press] = out[:press][i:sp]\n",
    "        end\n",
    "        push!(traces, tmp)\n",
    "        i = sp+1\n",
    "    end\n",
    "    \n",
    "    return traces\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "     split_conductivity_data(out;\n",
    "                             slice_cond=2.5,  # peaks are selected where cond is above this value\n",
    "                             slice_padding_start=20, # add a padding of in front of detected peak\n",
    "                             slice_padding_end=3*60, # add a padding of in back of detected peak\n",
    "                             mincond=0.5, maxtemp=3, # also drop points which have conductivity below mincond and above maxtemp\n",
    "                             smooth_window=10) # smoothing window used in peak detection\n",
    "\n",
    "Splits up the time series returned by `read_conductivity_data` into individual\n",
    "traces, mostly by heuristics around where peaks are.  A bit hit and miss.\n",
    "\n",
    "The output is a list of traces:\n",
    "\n",
    "`traces = [trace1, trace2, etc]`\n",
    "\n",
    "where `trace1` contains the time series with `:t` in seconds after recoding started, `:tstart` is\n",
    "the date-time of the start of the recording.  You should also add the injection `:mass` to each trace\n",
    "manually.\n",
    "\n",
    "Thus to access the times of the second trace do `traces[2][:t]`, and to get the corresponding\n",
    "conductivity readout `traces[2][:cond]`.\n",
    "\"\"\"\n",
    "function split_conductivity_data(out;\n",
    "                                 mincond=0.5, maxtemp=3,\n",
    "                                 slice_cond=2.5,\n",
    "                                 slice_padding_start=20,\n",
    "                                 slice_padding_end=3*60,\n",
    "                                 smooth_window=10)\n",
    "    out = deepcopy(out)\n",
    "\n",
    "    # smooth cond with running mean\n",
    "    cond = out[:cond]\n",
    "    t = out[:t]\n",
    "    condsmooth = zeros(length(cond))\n",
    "    for i=1:length(t)\n",
    "        ## running mean\n",
    "        tmp = 0.0\n",
    "        n = 0\n",
    "        for j=max(1,i-smooth_window):min(i+smooth_window, length(t))\n",
    "            tmp += cond[j]\n",
    "            n += 1\n",
    "        end\n",
    "        condsmooth[i] = tmp/n\n",
    "\n",
    "        # ## median\n",
    "        # condsmooth[i] = median(cond[max(1,i-smooth_window):min(i+smooth_window, length(t))])\n",
    "    end\n",
    "\n",
    "    # locate peaks with slice_cond and cut, also cut if time-gap bigger than timegap\n",
    "    inds = []\n",
    "\n",
    "    tokeep = condsmooth.>slice_cond\n",
    "    # add +/- slice_inds\n",
    "    s = 1\n",
    "    while true\n",
    "        s = findnext(tokeep, s)\n",
    "        if s==nothing\n",
    "            break\n",
    "        end\n",
    "        e = findnext(.!tokeep, s)\n",
    "        push!(inds, max(1, s-slice_padding_start):min(e+slice_padding_end, length(tokeep)))\n",
    "        s = e+1\n",
    "        if s>length(tokeep)\n",
    "            break\n",
    "        end\n",
    "    end\n",
    "\n",
    "    traces = []\n",
    "    i = 1\n",
    "    for ind in inds\n",
    "        tt = convert(Vector{Float64}, Dates.value.(t[ind]-t[ind[1]])/1000)\n",
    "        tmp = Dict{Symbol,Any}()\n",
    "\n",
    "        # delete where cond<mincond and temp>maxtemp\n",
    "        tokeep = (out[:cond][ind].>mincond) .& (out[:temp][ind].<maxtemp)\n",
    "\n",
    "        tmp[:t] = tt[tokeep]\n",
    "        tmp[:tstart] = t[ind][tokeep][1]\n",
    "        tmp[:cond] = cond[ind][tokeep]\n",
    "        tmp[:condsmooth] = condsmooth[ind][tokeep]\n",
    "        push!(traces, tmp)\n",
    "    end\n",
    "    return traces\n",
    "end\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    integrate_concentration(t, conc, t1=0.0, t2=Inf)\n",
    "\n",
    "Integrates the concentration time series.\n",
    "\n",
    "Input:\n",
    "- t -- times (s)\n",
    "- t1, t2 -- integrate from t1 to t2.  Note that the concentration should be \n",
    "            close to zero at both t1 and t2 as we want to integrate over the whole curve.\n",
    "- conc -- concentration (g/l) time series (convert conductivity with f_readout2conc \n",
    "          to a concentration)\n",
    "\n",
    "Output:\n",
    "\n",
    "- integrated concentration (g s/l) == (kg s/ m^3)\n",
    "\"\"\"\n",
    "function integrate_concentration(t, conc, t1=0.0, t2=Inf)\n",
    "    inds = findfirst(t.>=t1):findlast(t.<=t2)\n",
    "    dt = t[2]-t[1]\n",
    "    out = sum(conc[inds]*dt) # approximate the integral by a sum\n",
    "    return out\n",
    "end\n",
    "    \n",
    "\"\"\"\n",
    "    calcQ(trace, t1=0.0, t2=Inf, delta_cond2conc=delta_cond2conc)\n",
    "\n",
    "Calculate discharge from sensor readout.\n",
    "\n",
    "Input:\n",
    "- trace -- time series of sensor readout, including a field `:mass` with mass of salt injected\n",
    "\n",
    "Optional:\n",
    "- t1,t2 -- integration limits (otherwise the whole series is integrated)\n",
    "- delta_readout2conc -- if you got several `delta_readout2conc` functions, then\n",
    "                        pass it in explicitly.\n",
    "\n",
    "Output:\n",
    "- discharge Q (m^3/s)\n",
    "\"\"\"\n",
    "function calcQ(trace, t1=0.0, t2=Inf, delta_cond2conc=delta_cond2conc)\n",
    "    t, cond = trace[:t], trace[:cond]\n",
    "    i1, i2 = findfirst(t.>=t1), findlast(t.<=t2)\n",
    "    delta_cond = cond .- mean(cond[[i1,i2]])  #normalize from the actual conductivity background\n",
    "    for i in eachindex(delta_cond)\n",
    "        if delta_cond[i] < 0\n",
    "            delta_cond[i] = 0   #because negative cond lead to bug in exponent fit (complex number)\n",
    "        end\n",
    "    end\n",
    "    conc = delta_cond2conc(delta_cond)  #we take mean becasue conc is a particle \n",
    "\n",
    "    #uncertainty on mass = 1g = 0.001kg\n",
    "\n",
    "    return (trace[:mass] ± 0.001)/integrate_concentration(t, conc, t1, t2)\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "boxcar (generic function with 2 methods)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    boxcar(A::AbstractArray, window, [, weights, keepmask])\n",
    "    boxcar(A::AbstractArray, windows::Tuple, [, weights, keepmask])\n",
    "    boxcar(A::AbstractArray, window::AbstractArray, [, weights, keepmask])\n",
    "Boxcar filter.  The two argument call skips NaNs.  The three & four\n",
    "argument call uses weights and propagates NaNs, it can be a lot faster.\n",
    "Smoothing occurs over +/-window indices, 0 corresponds to no smoothing.\n",
    "The window can be specified as:\n",
    "- integer, for a symmetric window in all dimensions\n",
    "- a tuple to give lower and upper windows\n",
    "- a tuple of tuples to give different lower and upper windows for all dimensions\n",
    "- a array of size(A) for a different, symmetric window at each point.\n",
    "Weights, if given, will use those relative weights for averaging.  Note that\n",
    "points which have value==NaN and weight==0 will not poison the result.\n",
    "No average is calculated for points where keepmask==true, instead\n",
    "their original value will be kept.\n",
    "Notes:\n",
    "- For the weights it may be faster to use non-Bool arrays nor BitArrays,\n",
    "  say Int8.  Note that NaNs where weight==0 will not poison the result.\n",
    "- Also works for Vectors.\n",
    "From http://julialang.org/blog/2016/02/iteration\n",
    "\"\"\"\n",
    "boxcar(A::AbstractArray, window) = boxcar(A, (window,window))\n",
    "function boxcar(A::AbstractArray, windows::Tuple)\n",
    "    window_lower, window_upper = windows\n",
    "    out = similar(A)\n",
    "    R = CartesianIndices(size(A))\n",
    "    I1, Iend = first(R), last(R)\n",
    "    I_l = CartesianIndex(I1.I.*window_lower)\n",
    "    I_u = CartesianIndex(I1.I.*window_upper)\n",
    "    for I in R # @inbounds does not help\n",
    "        out[I] = NaN\n",
    "        n, s = 0, zero(eltype(out))\n",
    "        for J in CartesianIndices(UnitRange.(max(I1, I-I_l).I , min(Iend, I+I_u).I) ) # used to be\n",
    "        # for J in max(I1, I-I_l):min(Iend, I+I_u) ## in Julia 1.1\n",
    "            if !ismissing(A[J]) && !isnan(A[J])\n",
    "                s += A[J]\n",
    "                n += 1\n",
    "            end\n",
    "        end\n",
    "        out[I] = s/n\n",
    "    end\n",
    "    out\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "smooth_d"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "function smooth_d(d; windows)\n",
    "\n",
    "Smooth the time serie d (returned by read_keller) according to the windows asked. \n",
    "By default the smooth window of pressure time series is 10, for temperature (T) it is 30.\n",
    "\n",
    "\"\"\"\n",
    "function smooth_d(d; windows=Dict(:press=>10,\n",
    "                                  #:temp=>10,  #if add temp, make a test to find it : !isnothing\n",
    "                                  :temp2=>30))\n",
    "    out = Dict()\n",
    "    for (k,v) in windows\n",
    "        out[k] = boxcar(d[k], v)\n",
    "    end\n",
    "    return out\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "upscale_timeseries (generic function with 2 methods)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Statistics\n",
    "\"\"\"\n",
    "function upscale_timeseries(temp, t, period=\"period\")\n",
    "\n",
    "Up scale the time series : daily and hourly. The function returns the time serie averaged on each interval\n",
    "specified (day or hours).\n",
    "The mean for daily scale is associated at noon of the same day.\n",
    "\n",
    "The mean for hourly scale is associated at the beginnng of the hour.\n",
    "\n",
    "Achtung when there is NaN the mean dosn't take it, thus we should check if there is enough value in the time period\n",
    "considered to make the mean relevant\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "function upscale_timeseries(A, t, period=\"period\")\n",
    "    \n",
    "    if period == \"day\"\n",
    "\n",
    "A_daily = Float64[]\n",
    "A_daily_mean = []\n",
    "time_day = []\n",
    "\n",
    "d = day(t[1])\n",
    "mon = month(t[1])\n",
    "\n",
    "for i in 1:length(A)\n",
    "\n",
    "    if day(t[i]) == d && i !== length(A)\n",
    "        if !isnan(A[i])   \n",
    "        push!(A_daily, A[i])     \n",
    "        end\n",
    "                \n",
    "    elseif i == length(A) #To record daily mean even if the day is not complete - \n",
    "                                         #I made it to compute daily Q_lake until 27th July\n",
    "        avg = mean(A_daily)\n",
    "        push!(A_daily_mean, avg)\n",
    "        push!(time_day, DateTime(2019,mon,d))\n",
    "        empty!(A_daily)\n",
    "              \n",
    "\n",
    "    elseif day(t[i]) !== d && month(t[i]) == mon\n",
    "        \n",
    "        avg = mean(A_daily)\n",
    "        push!(A_daily_mean, avg)\n",
    "        push!(time_day, DateTime(2019,mon,d))\n",
    "        empty!(A_daily)\n",
    "        d = d + 1\n",
    "                \n",
    "        \n",
    "    elseif day(t[i]) !== d && month(t[i]) !== mon\n",
    "        \n",
    "        avg = mean(A_daily)\n",
    "        push!(A_daily_mean, avg)\n",
    "        push!(time_day, DateTime(2019,mon,d))\n",
    "        empty!(A_daily)\n",
    "        d = 1\n",
    "        mon = mon + 1\n",
    "    \n",
    "    end\n",
    "end\n",
    "    \n",
    "    return (time_day .+ Hour(12),A_daily_mean);\n",
    "    \n",
    "elseif period == \"hour\"\n",
    "        \n",
    "        A_hour = Float64[]\n",
    "        A_hour_mean = []\n",
    "        time_hour = []\n",
    "\n",
    "h = hour(t[1])\n",
    "d = day(t[1])\n",
    "mon = month(t[1])\n",
    "\n",
    "for i in 1:length(A)\n",
    "\n",
    "    if hour(t[i]) == h && day(t[i]) == d && month(t[i]) == mon\n",
    "        if !isnan(A[i])   \n",
    "        push!(A_hour, A[i])\n",
    "            \n",
    "        end\n",
    "    \n",
    "    elseif hour(t[i]) !== h && day(t[i]) == d && month(t[i]) == mon\n",
    "        \n",
    "        avg = mean(A_hour)\n",
    "        push!(A_hour_mean, avg)\n",
    "        push!(time_hour, DateTime(2019,mon,d,h))\n",
    "        empty!(A_hour)\n",
    "        h = h + 1\n",
    "        \n",
    "    elseif hour(t[i]) !== h && day(t[i]) !== d && month(t[i]) == mon\n",
    "        \n",
    "        avg = mean(A_hour)\n",
    "        push!(A_hour_mean, avg)\n",
    "        push!(time_hour, DateTime(2019,mon,d,h))\n",
    "        empty!(A_hour)\n",
    "        h = 0        \n",
    "        d = d + 1\n",
    "                \n",
    "    elseif hour(t[i]) !== h && day(t[i]) !== d && month(t[i]) !== mon\n",
    "        \n",
    "        avg = mean(A_hour)\n",
    "        push!(A_hour_mean, avg)\n",
    "        push!(time_hour, DateTime(2019,mon,d,h))\n",
    "        empty!(A_hour)\n",
    "        h = 0        \n",
    "        d = 1\n",
    "        mon = mon + 1\n",
    "                \n",
    "    end\n",
    "end\n",
    "    \n",
    "    return (time_hour,A_hour_mean);\n",
    "        \n",
    "end\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to convert the DateTime in decimal to interpolation x axis -- Start the 9th July --> End August\n",
    "# Temporal resolution : minute\n",
    "using Dates\n",
    "\n",
    "function datetime2decimal(t::DateTime)\n",
    "    if Dates.month(t) == 7     \n",
    "        d = Dates.day(t) - 8  ## start 9th July ##\n",
    "        \n",
    "    elseif Dates.month(t) == 8\n",
    "        d = Dates.day(t) + 31 - 8 #31 days in July\n",
    "        \n",
    "    elseif Dates.month(t) == 9  \n",
    "        d = Dates.day(t) + 31 - 8 + 31 # 31th days in Aungust    \n",
    "    end\n",
    "    h = Dates.hour(t)    \n",
    "    m = Dates.minute(t)   \n",
    "    time_dec = d + h/24 + m/(24*60);\n",
    "    end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "isnan_part"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "function isnan_part(x) \n",
    "\n",
    "(part for particles)\n",
    "\n",
    "Return false is x is a particle, true if there is a NaN or Inf\n",
    "Remark: isnan(NaN ± Inf) is false, isnan_part(x) is true\n",
    "\n",
    "Note: this automatically throw an error if there is a NaN (instead of a Inf) behind the ±\n",
    "Todo: catch this error too\n",
    "\"\"\"\n",
    "function isnan_part(x)\n",
    "    \n",
    "try (x).particles\n",
    "    catch e\n",
    "    throw(e) #throw error if x is not a particle\n",
    "end\n",
    "    if isnan(mean(x)) || isnan(std(x))\n",
    "        return true\n",
    "    else\n",
    "        return false\n",
    "    end\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "reynolds(h, w, q)\n",
    "\n",
    "input :\n",
    "-- h water stage (m)\n",
    "-- w width (m)\n",
    "-- q discharge (m3/s)\n",
    "\n",
    "h and q have the same dimension\n",
    "\n",
    "Assuming a rectangular cross-section\n",
    "\n",
    "output:\n",
    "--reynolds number at one cross section\n",
    "\n",
    "\"\"\"\n",
    "function reynolds(h, w, q)\n",
    "    η = 1.8E-6; #kinematic viscosity of water\n",
    "    Pw = @. w + 2*h # wetted perimeter: rectangular cross section\n",
    "    A = @. w*h\n",
    "    return @. (q*4)/(η*Pw)\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\" \n",
    "stream_veloctiy(h, w, q)\n",
    "\n",
    "input :\n",
    "-- h water stage (m)\n",
    "-- w width (m)\n",
    "-- q discharge (m3/s)\n",
    "\n",
    "h and q have the same dimension\n",
    "\n",
    "Assuming a rectangular cross-section\n",
    "\n",
    "output:\n",
    "--The averaged stream velocity at the cross section\n",
    "\n",
    "\"\"\"\n",
    "function stream_velocity(h, w, q)\n",
    "    A = @. w*h # rectangular wetted cross section\n",
    "    return @. q/A  #the latter is the velocity associated to reynolds calculation\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Format de la Cellule Texte Brut",
  "kernelspec": {
   "display_name": "Julia 1.5.1",
   "language": "julia",
   "name": "julia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
